{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1f932d4dff1c48d4b9c1b1b1e54692d3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb088327aa2a4651af11fd9e27eea118","IPY_MODEL_d59184136c8846eaacd83e11ac3b9e41","IPY_MODEL_a1bfefbb51fc42cabf3828da19095db4"],"layout":"IPY_MODEL_dbc626ca7cc446a9a5cac2310cab25cd"}},"bb088327aa2a4651af11fd9e27eea118":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41fad094a1064cb4bf5134d5e2ebf54e","placeholder":"​","style":"IPY_MODEL_8d796788d43b4db6bd25dbc99001adf2","value":"tokenizer_config.json: 100%"}},"d59184136c8846eaacd83e11ac3b9e41":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b15fa34bc4c841f08967255ebd92249d","max":1172,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc399102bb374a798d3ee6b7a3a3cb61","value":1172}},"a1bfefbb51fc42cabf3828da19095db4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea6543b1d8d5435e926c00bb9c5e0137","placeholder":"​","style":"IPY_MODEL_3a301e58c86646d292e85477807fec58","value":" 1.17k/1.17k [00:00&lt;00:00, 37.6kB/s]"}},"dbc626ca7cc446a9a5cac2310cab25cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41fad094a1064cb4bf5134d5e2ebf54e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d796788d43b4db6bd25dbc99001adf2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b15fa34bc4c841f08967255ebd92249d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc399102bb374a798d3ee6b7a3a3cb61":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ea6543b1d8d5435e926c00bb9c5e0137":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a301e58c86646d292e85477807fec58":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7b823165f64463489e9aafcf546bd6d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_df93503865f5492cba3ad460d876156a","IPY_MODEL_3ebcfb687c48467faa6ceb602ff4487f","IPY_MODEL_0f86608377fb48d4a8aba579ed5e53ee"],"layout":"IPY_MODEL_a74cb4d0ef0147d6a2b64120458c5290"}},"df93503865f5492cba3ad460d876156a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1f65d4fc47245bdaf70529c7d5c211c","placeholder":"​","style":"IPY_MODEL_a50cc223d7aa4ce4b80641a7cd60c688","value":"vocab.txt: 100%"}},"3ebcfb687c48467faa6ceb602ff4487f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5cf99b29adc74153bb77bf32f8eb8797","max":895321,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3c547a9cc8314278b942b02da4edfb5f","value":895321}},"0f86608377fb48d4a8aba579ed5e53ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae5880843b3049f29ea4cb0440182ca5","placeholder":"​","style":"IPY_MODEL_7ab92c55cafd4737a59720f399c495d2","value":" 895k/895k [00:00&lt;00:00, 3.43MB/s]"}},"a74cb4d0ef0147d6a2b64120458c5290":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1f65d4fc47245bdaf70529c7d5c211c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a50cc223d7aa4ce4b80641a7cd60c688":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5cf99b29adc74153bb77bf32f8eb8797":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c547a9cc8314278b942b02da4edfb5f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ae5880843b3049f29ea4cb0440182ca5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ab92c55cafd4737a59720f399c495d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1884197e8928431ab8a1b37ced64943c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b2ab104495b341cd87a39a470fd41f12","IPY_MODEL_6bad9dde7e714bf195f4486cfdde84dc","IPY_MODEL_c7938934d97647d7b9a117ebe4e99641"],"layout":"IPY_MODEL_d20248bee68c42e2a62352aeea842a4d"}},"b2ab104495b341cd87a39a470fd41f12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b217d93702e4f9fa0628c40cf5e83f7","placeholder":"​","style":"IPY_MODEL_bb5765352c294402a426a96fbb6a00ff","value":"bpe.codes: 100%"}},"6bad9dde7e714bf195f4486cfdde84dc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_16860026ed474d1e92824806c011acaf","max":1135173,"min":0,"orientation":"horizontal","style":"IPY_MODEL_407b5abfccea4e979a8864ac8e74818e","value":1135173}},"c7938934d97647d7b9a117ebe4e99641":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ddf13c70bad94446b4299bf3668d4e62","placeholder":"​","style":"IPY_MODEL_a59e3bbc19f24892836b4c6522f05e30","value":" 1.14M/1.14M [00:00&lt;00:00, 3.67MB/s]"}},"d20248bee68c42e2a62352aeea842a4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b217d93702e4f9fa0628c40cf5e83f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb5765352c294402a426a96fbb6a00ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16860026ed474d1e92824806c011acaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"407b5abfccea4e979a8864ac8e74818e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ddf13c70bad94446b4299bf3668d4e62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a59e3bbc19f24892836b4c6522f05e30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5e0cac8f3be4007adc775990d2fdc0d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_88991c6b114340ffb0e00f36bdd21dd2","IPY_MODEL_5f72b3852e074aeea4a2819bc08d1a60","IPY_MODEL_a7c5f20983ce40e8b3ee22b68041a4b4"],"layout":"IPY_MODEL_977ba1e4e12f4fe5b55aad8e8e397f49"}},"88991c6b114340ffb0e00f36bdd21dd2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d183981136154345975ff850550d591d","placeholder":"​","style":"IPY_MODEL_437baf368e5e4286b7c8735bdd055159","value":"added_tokens.json: 100%"}},"5f72b3852e074aeea4a2819bc08d1a60":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f80a7855b51e4bd595ab7c107ac8c50e","max":22,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec62ebed80de4bc2aaf0926ec8d6ac14","value":22}},"a7c5f20983ce40e8b3ee22b68041a4b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f7e59b73fec4e9086cd275cc32b0d39","placeholder":"​","style":"IPY_MODEL_b37a3fb3699544aaa220bc77ccd36d4b","value":" 22.0/22.0 [00:00&lt;00:00, 566B/s]"}},"977ba1e4e12f4fe5b55aad8e8e397f49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d183981136154345975ff850550d591d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"437baf368e5e4286b7c8735bdd055159":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f80a7855b51e4bd595ab7c107ac8c50e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec62ebed80de4bc2aaf0926ec8d6ac14":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8f7e59b73fec4e9086cd275cc32b0d39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b37a3fb3699544aaa220bc77ccd36d4b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a0766d375a724412840a9dead880639c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f77d8c6a38af45c7bfdc18f6faaaf48f","IPY_MODEL_dfc5ce8d603a4f89bdca74316439fe6e","IPY_MODEL_d96ae92c0cca45bbb61b4c4641aeddf5"],"layout":"IPY_MODEL_3266a1bf253e4596b752bfea7ce973d3"}},"f77d8c6a38af45c7bfdc18f6faaaf48f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_265496b5b08c4be69575dd2f017b0800","placeholder":"​","style":"IPY_MODEL_179adb8d2a6c4fed8094d7d502677112","value":"special_tokens_map.json: 100%"}},"dfc5ce8d603a4f89bdca74316439fe6e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8638112c20d748549e5758b3dced5ef6","max":167,"min":0,"orientation":"horizontal","style":"IPY_MODEL_85adf5e148cb457cbe1b9edc5b120297","value":167}},"d96ae92c0cca45bbb61b4c4641aeddf5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1efbfbefe1ff47d49983d7d8ac43fe48","placeholder":"​","style":"IPY_MODEL_8b9c451f85f74a7da2f6b3729df8e1fe","value":" 167/167 [00:00&lt;00:00, 3.37kB/s]"}},"3266a1bf253e4596b752bfea7ce973d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"265496b5b08c4be69575dd2f017b0800":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"179adb8d2a6c4fed8094d7d502677112":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8638112c20d748549e5758b3dced5ef6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85adf5e148cb457cbe1b9edc5b120297":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1efbfbefe1ff47d49983d7d8ac43fe48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b9c451f85f74a7da2f6b3729df8e1fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!conda install -y gdown\nimport gdown","metadata":{"execution":{"iopub.status.busy":"2024-11-17T07:47:45.016878Z","iopub.execute_input":"2024-11-17T07:47:45.017682Z","iopub.status.idle":"2024-11-17T07:49:13.676727Z","shell.execute_reply.started":"2024-11-17T07:47:45.017647Z","shell.execute_reply":"2024-11-17T07:49:13.675728Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Retrieving notices: ...working... done\nChannels:\n - rapidsai\n - nvidia\n - nodefaults\n - conda-forge\n - defaults\n - pytorch\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda\n\n  added / updated specs:\n    - gdown\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    conda-24.9.2               |  py310hff52083_0         895 KB  conda-forge\n    filelock-3.16.1            |     pyhd8ed1ab_0          17 KB  conda-forge\n    gdown-5.2.0                |     pyhd8ed1ab_0          21 KB  conda-forge\n    openssl-3.4.0              |       hb9d3cd8_0         2.8 MB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         3.7 MB\n\nThe following NEW packages will be INSTALLED:\n\n  filelock           conda-forge/noarch::filelock-3.16.1-pyhd8ed1ab_0 \n  gdown              conda-forge/noarch::gdown-5.2.0-pyhd8ed1ab_0 \n\nThe following packages will be UPDATED:\n\n  conda                              24.9.0-py310hff52083_0 --> 24.9.2-py310hff52083_0 \n  openssl                                  3.3.2-hb9d3cd8_0 --> 3.4.0-hb9d3cd8_0 \n\n\n\nDownloading and Extracting Packages:\nopenssl-3.4.0        | 2.8 MB    |                                       |   0% \nconda-24.9.2         | 895 KB    |                                       |   0% \u001b[A\n\ngdown-5.2.0          | 21 KB     |                                       |   0% \u001b[A\u001b[A\n\n\nfilelock-3.16.1      | 17 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\nopenssl-3.4.0        | 2.8 MB    | 8                                     |   2% \u001b[A\n\n\nfilelock-3.16.1      | 17 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n\n\nfilelock-3.16.1      | 17 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n\ngdown-5.2.0          | 21 KB     | ##################################### | 100% \u001b[A\u001b[A\n\nopenssl-3.4.0        | 2.8 MB    | ##################################### | 100% \u001b[A\u001b[A\nconda-24.9.2         | 895 KB    | ##################################### | 100% \u001b[A\n                                                                                \u001b[A\n                                                                                \u001b[A\n\n                                                                                \u001b[A\u001b[A\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\n","output_type":"stream"}]},{"cell_type":"code","source":"train_url = 'https://drive.google.com/uc?id=16434ij3b-G-uIxr1-x8kRq3qRWR_GeAT'\ndev_url = 'https://drive.google.com/uc?id=1zOWtEwscZM4x-m39s4Ib9g_OmOQ8inFI'\ntest_url = 'https://drive.google.com/uc?id=1NqRGgVuiLqbkiV9p-pNvKk3C93EAM-xh'\nw2v_url = 'https://drive.google.com/uc?id=1PBiofrHGe4z9tj8X9hjU6WlKk93ZGxHL'\n\ntrain_out = 'Train_preprocessed_with_-1.csv'\ndev_out = 'dev_final.csv'\ntest_out = 'test_final.csv'\nw2v_out = 'W2V_150.txt'\n\ngdown.download(train_url, train_out, quiet=False)\ngdown.download(dev_url, dev_out, quiet=False)\ngdown.download(test_url, test_out, quiet=False)\ngdown.download(w2v_url, w2v_out, quiet=False)","metadata":{"execution":{"iopub.status.busy":"2024-11-17T07:49:13.679962Z","iopub.execute_input":"2024-11-17T07:49:13.680544Z","iopub.status.idle":"2024-11-17T07:49:30.467181Z","shell.execute_reply.started":"2024-11-17T07:49:13.680498Z","shell.execute_reply":"2024-11-17T07:49:30.466274Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"Downloading...\nFrom: https://drive.google.com/uc?id=16434ij3b-G-uIxr1-x8kRq3qRWR_GeAT\nTo: /kaggle/working/Train_preprocessed_with_-1.csv\n100%|██████████| 2.30M/2.30M [00:00<00:00, 161MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1zOWtEwscZM4x-m39s4Ib9g_OmOQ8inFI\nTo: /kaggle/working/dev_final.csv\n100%|██████████| 319k/319k [00:00<00:00, 84.4MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1NqRGgVuiLqbkiV9p-pNvKk3C93EAM-xh\nTo: /kaggle/working/test_final.csv\n100%|██████████| 654k/654k [00:00<00:00, 113MB/s]\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1PBiofrHGe4z9tj8X9hjU6WlKk93ZGxHL\nFrom (redirected): https://drive.google.com/uc?id=1PBiofrHGe4z9tj8X9hjU6WlKk93ZGxHL&confirm=t&uuid=a3613f0d-f396-41f5-b3d3-c9ee3502397d\nTo: /kaggle/working/W2V_150.txt\n100%|██████████| 119M/119M [00:01<00:00, 72.8MB/s] \n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'W2V_150.txt'"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport torch.nn as nn\nfrom torch.nn.functional import softmax\nfrom tqdm import tqdm\nfrom transformers import AutoTokenizer\nfrom sklearn.metrics import precision_score, recall_score, f1_score","metadata":{"id":"lPR2wIJQf-PB","execution":{"iopub.status.busy":"2024-11-17T07:49:30.468360Z","iopub.execute_input":"2024-11-17T07:49:30.468662Z","iopub.status.idle":"2024-11-17T07:49:34.188664Z","shell.execute_reply.started":"2024-11-17T07:49:30.468630Z","shell.execute_reply":"2024-11-17T07:49:34.187684Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-11-17T07:49:34.190869Z","iopub.execute_input":"2024-11-17T07:49:34.191373Z","iopub.status.idle":"2024-11-17T07:49:34.229161Z","shell.execute_reply.started":"2024-11-17T07:49:34.191339Z","shell.execute_reply":"2024-11-17T07:49:34.228151Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Define aspect and sentiment mappings\naspect2idx = {\n    'CAMERA': 0, 'FEATURES': 1, 'BATTERY': 2, 'PERFORMANCE': 3,\n    'DESIGN': 4, 'GENERAL': 5, 'PRICE': 6, 'SCREEN': 7, 'SER&ACC': 8, 'STORAGE': 9\n}\nsentiment2idx = {\n    'Positive': 2, 'Neutral': 1, 'Negative': 0\n}\nnum_aspect = len(aspect2idx)\n\n# Convert label cell to tensor\ndef convert_label(cell):\n    return torch.tensor([float(x) for x in cell.strip('[]').split()])\n\n# Load train data\ntrain = pd.read_csv(\"Train_preprocessed_with_-1.csv\")\nsentences_train = list(train['comment'])\nlabels_train = list(train['label'].apply(convert_label))\n\n# Initialize tokenizer\ntokenizer = AutoTokenizer.from_pretrained('bkai-foundation-models/vietnamese-bi-encoder')","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281,"referenced_widgets":["1f932d4dff1c48d4b9c1b1b1e54692d3","bb088327aa2a4651af11fd9e27eea118","d59184136c8846eaacd83e11ac3b9e41","a1bfefbb51fc42cabf3828da19095db4","dbc626ca7cc446a9a5cac2310cab25cd","41fad094a1064cb4bf5134d5e2ebf54e","8d796788d43b4db6bd25dbc99001adf2","b15fa34bc4c841f08967255ebd92249d","dc399102bb374a798d3ee6b7a3a3cb61","ea6543b1d8d5435e926c00bb9c5e0137","3a301e58c86646d292e85477807fec58","d7b823165f64463489e9aafcf546bd6d","df93503865f5492cba3ad460d876156a","3ebcfb687c48467faa6ceb602ff4487f","0f86608377fb48d4a8aba579ed5e53ee","a74cb4d0ef0147d6a2b64120458c5290","b1f65d4fc47245bdaf70529c7d5c211c","a50cc223d7aa4ce4b80641a7cd60c688","5cf99b29adc74153bb77bf32f8eb8797","3c547a9cc8314278b942b02da4edfb5f","ae5880843b3049f29ea4cb0440182ca5","7ab92c55cafd4737a59720f399c495d2","1884197e8928431ab8a1b37ced64943c","b2ab104495b341cd87a39a470fd41f12","6bad9dde7e714bf195f4486cfdde84dc","c7938934d97647d7b9a117ebe4e99641","d20248bee68c42e2a62352aeea842a4d","4b217d93702e4f9fa0628c40cf5e83f7","bb5765352c294402a426a96fbb6a00ff","16860026ed474d1e92824806c011acaf","407b5abfccea4e979a8864ac8e74818e","ddf13c70bad94446b4299bf3668d4e62","a59e3bbc19f24892836b4c6522f05e30","a5e0cac8f3be4007adc775990d2fdc0d","88991c6b114340ffb0e00f36bdd21dd2","5f72b3852e074aeea4a2819bc08d1a60","a7c5f20983ce40e8b3ee22b68041a4b4","977ba1e4e12f4fe5b55aad8e8e397f49","d183981136154345975ff850550d591d","437baf368e5e4286b7c8735bdd055159","f80a7855b51e4bd595ab7c107ac8c50e","ec62ebed80de4bc2aaf0926ec8d6ac14","8f7e59b73fec4e9086cd275cc32b0d39","b37a3fb3699544aaa220bc77ccd36d4b","a0766d375a724412840a9dead880639c","f77d8c6a38af45c7bfdc18f6faaaf48f","dfc5ce8d603a4f89bdca74316439fe6e","d96ae92c0cca45bbb61b4c4641aeddf5","3266a1bf253e4596b752bfea7ce973d3","265496b5b08c4be69575dd2f017b0800","179adb8d2a6c4fed8094d7d502677112","8638112c20d748549e5758b3dced5ef6","85adf5e148cb457cbe1b9edc5b120297","1efbfbefe1ff47d49983d7d8ac43fe48","8b9c451f85f74a7da2f6b3729df8e1fe"]},"id":"cQ7xKa3agRQm","executionInfo":{"status":"ok","timestamp":1731780918425,"user_tz":-420,"elapsed":6310,"user":{"displayName":"Trường Nguyễn","userId":"01798196861580803215"}},"outputId":"9ddebc8e-54f7-4dff-9aef-76fdbcfb4c27","execution":{"iopub.status.busy":"2024-11-17T07:49:34.230733Z","iopub.execute_input":"2024-11-17T07:49:34.231157Z","iopub.status.idle":"2024-11-17T07:49:36.358021Z","shell.execute_reply.started":"2024-11-17T07:49:34.231091Z","shell.execute_reply":"2024-11-17T07:49:36.356997Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"faed36cc8a264ff8b0795cf2f7170963"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74b5e9d4355f4dfcb19ffae83aea9c4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b2aa1760d19475091e04678185ffb72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/22.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4bad31f96ff476ab90772b0ccaab52f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e93977073f34df0ae9b6fb990f978b0"}},"metadata":{}}]},{"cell_type":"code","source":"# Define dataset\nclass CustomTextDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length=128):\n        self.texts = texts\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        labels = torch.tensor(self.labels[idx], dtype=torch.float32)\n        encoding = self.tokenizer(text, padding='max_length', truncation=True, max_length=self.max_length, return_tensors='pt')\n        dic = {key: val.squeeze(0) for key, val in encoding.items()}\n        dic['labels'] = labels\n        return dic","metadata":{"id":"xW-Y1qO4YZpw","execution":{"iopub.status.busy":"2024-11-17T07:49:36.359501Z","iopub.execute_input":"2024-11-17T07:49:36.359829Z","iopub.status.idle":"2024-11-17T07:49:36.366944Z","shell.execute_reply.started":"2024-11-17T07:49:36.359796Z","shell.execute_reply":"2024-11-17T07:49:36.365964Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Create dataset and dataloader\ntrain_dataset = CustomTextDataset(sentences_train, labels_train, tokenizer)\ntrain_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=128)\n\ndev = pd.read_csv('dev_final.csv')\nsentences_dev = list(dev['comment'])\nlabels_dev = list(dev['label'].apply(convert_label))\n\ndev_dataset = CustomTextDataset(sentences_dev, labels_dev, tokenizer)\ndev_dataloader = DataLoader(dev_dataset, shuffle=True, batch_size=128)","metadata":{"execution":{"iopub.status.busy":"2024-11-17T07:49:36.368147Z","iopub.execute_input":"2024-11-17T07:49:36.368447Z","iopub.status.idle":"2024-11-17T07:49:36.421024Z","shell.execute_reply.started":"2024-11-17T07:49:36.368416Z","shell.execute_reply":"2024-11-17T07:49:36.420335Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class AttentionInHtt(nn.Module):\n    def __init__(self, in_features, out_features, bias=True, softmax=True):\n        super().__init__()\n        self.W = nn.Linear(in_features, out_features, bias)\n        self.uw = nn.Linear(out_features, 1, bias=False)\n        self.softmax = softmax\n\n    def forward(self, h: torch.Tensor, mask: torch.Tensor):\n        u = self.W(h)  # (batch_size, seq_len, out_features)\n        u = torch.tanh(u)\n        similarities = self.uw(u)  # (batch_size, seq_len, 1)\n        similarities = similarities.squeeze(dim=-1)  # (batch_size, seq_len)\n\n        # Mask the similarities\n        similarities = similarities.masked_fill(~mask.bool(), -float('inf'))\n\n        if self.softmax:\n            alpha = torch.softmax(similarities, dim=-1)\n            return alpha\n        else:\n            return similarities\n            # return attention score","metadata":{"id":"Ge9Phl8xlzU3","execution":{"iopub.status.busy":"2024-11-17T07:49:36.422035Z","iopub.execute_input":"2024-11-17T07:49:36.422356Z","iopub.status.idle":"2024-11-17T07:49:36.430111Z","shell.execute_reply.started":"2024-11-17T07:49:36.422323Z","shell.execute_reply":"2024-11-17T07:49:36.429166Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def element_wise_mul(input1, input2, return_not_sum_result=False):\n        output = input1 * input2.unsqueeze(2)  # Ensure correct broadcasting\n        result = output.sum(dim=1)\n        if return_not_sum_result:\n            return result, output\n        else:\n            return result","metadata":{"id":"7cPVC7hx1BeQ","execution":{"iopub.status.busy":"2024-11-17T07:49:36.431423Z","iopub.execute_input":"2024-11-17T07:49:36.432367Z","iopub.status.idle":"2024-11-17T07:49:36.440213Z","shell.execute_reply.started":"2024-11-17T07:49:36.432309Z","shell.execute_reply":"2024-11-17T07:49:36.439367Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class Cae(nn.Module):\n    def __init__(self, word_embedder, categories, polarities):\n        super().__init__()\n        self.word_embedder = word_embedder\n        self.category_num = len(categories)\n        self.polarity_num = len(polarities)\n        self.category_loss = nn.BCEWithLogitsLoss()\n        self.sentiment_loss = nn.CrossEntropyLoss(ignore_index=-1)\n\n        embed_dim = word_embedder.embedding_dim\n        self.embedding_layer_fc = nn.Linear(embed_dim, embed_dim)\n        self.embedding_layer_aspect_attentions = nn.ModuleList([AttentionInHtt(embed_dim, embed_dim) for _ in range(self.category_num)])\n        self.lstm_layer_aspect_attentions = nn.ModuleList([AttentionInHtt(embed_dim, embed_dim) for _ in range(self.category_num)])\n\n        self.lstm = nn.LSTM(embed_dim, embed_dim // 2, batch_first=True, bidirectional=True)\n        self.dropout_after_embedding = nn.Dropout(0.5)\n        self.dropout_after_lstm = nn.Dropout(0.5)\n\n        self.category_fcs = nn.ModuleList([nn.Sequential(nn.Linear(embed_dim * 2, 32), nn.ReLU(), nn.Linear(32, 1)) for _ in range(self.category_num)])\n        self.sentiment_fc = nn.Sequential(nn.Linear(embed_dim * 2, 32), nn.ReLU(), nn.Linear(32, self.polarity_num))\n\n    def forward(self, tokens, labels, mask, threshold=0.25):\n        word_embeddings = self.word_embedder(tokens)\n        word_embeddings = self.dropout_after_embedding(word_embeddings)\n\n        embeddings = word_embeddings\n        embedding_layer_category_outputs = []\n        embedding_layer_sentiment_outputs = []\n        for i in range(self.category_num):\n            embedding_layer_aspect_attention = self.embedding_layer_aspect_attentions[i]\n            alpha = embedding_layer_aspect_attention(embeddings, mask)\n\n            category_output = element_wise_mul(embeddings, alpha)\n            embedding_layer_category_outputs.append(category_output)\n\n            category_output = category_output.unsqueeze(1)\n            sentiment_alpha = torch.matmul(category_output, embeddings.transpose(1, 2)).squeeze(1)\n            sentiment_alpha = softmax(sentiment_alpha, dim=-1)\n            sentiment_output = torch.matmul(sentiment_alpha.unsqueeze(1), word_embeddings).squeeze(1)\n            embedding_layer_sentiment_outputs.append(sentiment_output)\n\n        lstm_result, _ = self.lstm(word_embeddings)\n        lstm_result = self.dropout_after_lstm(lstm_result)\n\n        lstm_layer_category_outputs = []\n        lstm_layer_sentiment_outputs = []\n        for i in range(self.category_num):\n            lstm_layer_aspect_attention = self.lstm_layer_aspect_attentions[i]\n            alpha = lstm_layer_aspect_attention(lstm_result, mask)\n            category_output = element_wise_mul(lstm_result, alpha)\n            lstm_layer_category_outputs.append(category_output)\n\n            category_output = category_output.unsqueeze(1)\n            sentiment_alpha = torch.matmul(category_output, lstm_result.transpose(1, 2)).squeeze(1)\n            sentiment_alpha = softmax(sentiment_alpha, dim=-1)\n            sentiment_output = torch.matmul(sentiment_alpha.unsqueeze(1), lstm_result).squeeze(1)\n            lstm_layer_sentiment_outputs.append(sentiment_output)\n\n        final_category_outputs = []\n        final_sentiment_outputs = []\n        for i in range(self.category_num):\n            fc = self.category_fcs[i]\n            category_output = torch.cat([embedding_layer_category_outputs[i], lstm_layer_category_outputs[i]], dim=-1)\n            final_category_output = fc(category_output)\n            final_category_outputs.append(final_category_output)\n\n            sentiment_output = torch.cat([embedding_layer_sentiment_outputs[i], lstm_layer_sentiment_outputs[i]], dim=-1)\n            final_sentiment_output = self.sentiment_fc(sentiment_output)\n            final_sentiment_outputs.append(final_sentiment_output)\n\n        loss = 0\n        if labels is not None:\n            category_labels = labels[:, :self.category_num]\n            polarity_labels = labels[:, self.category_num:]\n\n            for i in range(self.category_num):\n                category_mask = (category_labels[:, i] != -1)  # Mask out ignored labels\n                sentiment_mask = (polarity_labels[:, i] != -1)\n\n                if category_mask.any():  # Only calculate if there are valid labels\n                    category_temp_loss = self.category_loss(final_category_outputs[i].squeeze(-1)[category_mask], category_labels[:, i][category_mask])\n                    loss += category_temp_loss\n\n                if sentiment_mask.any():  # Only calculate if there are valid labels\n                    sentiment_temp_loss = self.sentiment_loss(final_sentiment_outputs[i][sentiment_mask], polarity_labels[:, i][sentiment_mask].long())\n                    loss += sentiment_temp_loss\n\n#         output = {\n#             'pred_category': [torch.sigmoid(e) for e in final_category_outputs],\n#             'pred_sentiment': [torch.softmax(e, dim=-1) for e in final_sentiment_outputs]\n#         }\n        # formatting output\n        final_category_outputs = [torch.sigmoid(e) for e in final_category_outputs]\n        final_sentiment_outputs = [torch.softmax(e, dim=-1) for e in final_sentiment_outputs]\n        final_sentiment_outputs = [torch.argmax(e, dim=-1) for e in final_sentiment_outputs]\n        \n        final_categories = []\n        final_sentiments = []\n\n        for i in range(len(final_category_outputs)):\n            batch_category = []\n            batch_sentiment = []\n            for j, category_score in enumerate(final_category_outputs[i]):\n                # Apply threshold for aspect detection\n                if category_score >= threshold:\n                    batch_category.append(1)  # Aspect detected\n                    batch_sentiment.append(final_sentiment_outputs[i][j].item())\n                else:\n                    batch_category.append(0)  # Aspect not detected\n                    batch_sentiment.append(-1)  # Set sentiment to -1 for undetected aspect\n            final_categories.append(batch_category)\n            final_sentiments.append(batch_sentiment)\n        final_categories = torch.tensor(final_categories)\n        final_sentiments = torch.tensor(final_sentiments)\n        \n        output = {\n            'pred_category': torch.transpose(final_categories, 0, 1), # batch_size*10\n            'pred_sentiment': torch.transpose(final_sentiments, 0, 1) # batch_size*10\n        }\n\n        return output, loss","metadata":{"id":"O4RNz-u71gGu","execution":{"iopub.status.busy":"2024-11-17T07:49:36.443696Z","iopub.execute_input":"2024-11-17T07:49:36.443975Z","iopub.status.idle":"2024-11-17T07:49:36.471204Z","shell.execute_reply.started":"2024-11-17T07:49:36.443946Z","shell.execute_reply":"2024-11-17T07:49:36.470376Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"w2v = 'W2V_150.txt'\nembedding_dim = 150\nword_to_vec = {}\nwith open(w2v, 'r', encoding='utf-8') as file:\n    for line in file:\n        values = line.split()\n        word = values[0]\n        vector = np.asarray(values[1:], dtype='float32')\n        word_to_vec[word] = vector\n\nvocab = tokenizer.get_vocab()\nvocab_size = len(vocab)\nE = np.zeros((vocab_size, embedding_dim))\nfor word, idx in vocab.items():\n    E[idx] = word_to_vec.get(word, np.random.normal(scale=0.6, size=(embedding_dim,)))\n\nembedding_matrix = torch.tensor(E, dtype=torch.float32)\nembedding_layer = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)","metadata":{"id":"tuh61NSB-E6t","execution":{"iopub.status.busy":"2024-11-17T07:49:36.472272Z","iopub.execute_input":"2024-11-17T07:49:36.472837Z","iopub.status.idle":"2024-11-17T07:49:40.758003Z","shell.execute_reply.started":"2024-11-17T07:49:36.472800Z","shell.execute_reply":"2024-11-17T07:49:40.757026Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"categories = aspect2idx.keys()\npolarities = sentiment2idx.keys()\nmodel = Cae(embedding_layer, categories, polarities)\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-4)","metadata":{"id":"rlOcjTUdASnG","execution":{"iopub.status.busy":"2024-11-17T07:49:40.759229Z","iopub.execute_input":"2024-11-17T07:49:40.759551Z","iopub.status.idle":"2024-11-17T07:49:41.702614Z","shell.execute_reply.started":"2024-11-17T07:49:40.759512Z","shell.execute_reply":"2024-11-17T07:49:41.701836Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-11-17T07:49:41.703737Z","iopub.execute_input":"2024-11-17T07:49:41.704248Z","iopub.status.idle":"2024-11-17T07:49:41.945091Z","shell.execute_reply.started":"2024-11-17T07:49:41.704213Z","shell.execute_reply":"2024-11-17T07:49:41.944169Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Cae(\n  (word_embedder): Embedding(64001, 150)\n  (category_loss): BCEWithLogitsLoss()\n  (sentiment_loss): CrossEntropyLoss()\n  (embedding_layer_fc): Linear(in_features=150, out_features=150, bias=True)\n  (embedding_layer_aspect_attentions): ModuleList(\n    (0-9): 10 x AttentionInHtt(\n      (W): Linear(in_features=150, out_features=150, bias=True)\n      (uw): Linear(in_features=150, out_features=1, bias=False)\n    )\n  )\n  (lstm_layer_aspect_attentions): ModuleList(\n    (0-9): 10 x AttentionInHtt(\n      (W): Linear(in_features=150, out_features=150, bias=True)\n      (uw): Linear(in_features=150, out_features=1, bias=False)\n    )\n  )\n  (lstm): LSTM(150, 75, batch_first=True, bidirectional=True)\n  (dropout_after_embedding): Dropout(p=0.5, inplace=False)\n  (dropout_after_lstm): Dropout(p=0.5, inplace=False)\n  (category_fcs): ModuleList(\n    (0-9): 10 x Sequential(\n      (0): Linear(in_features=300, out_features=32, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=32, out_features=1, bias=True)\n    )\n  )\n  (sentiment_fc): Sequential(\n    (0): Linear(in_features=300, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=3, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# def infer_batch(input_ids, attention_mask, threshold=0.65):\n#     # Set the model to evaluation mode\n#     model.eval()\n\n#     with torch.no_grad():\n#         # Forward pass through the model\n#         output, loss = model(tokens=input_ids, labels=None, mask=attention_mask)\n\n#     return {\n#         \"Detected Aspects\": output['pred_category'], # batch_size*10\n#         \"Aspect Sentiments\": output['pred_sentiment'] # batch_size*10\n#     }","metadata":{"id":"Xjq5ECJTUEB3","execution":{"iopub.status.busy":"2024-11-17T07:49:41.946433Z","iopub.execute_input":"2024-11-17T07:49:41.946821Z","iopub.status.idle":"2024-11-17T07:49:41.951982Z","shell.execute_reply.started":"2024-11-17T07:49:41.946778Z","shell.execute_reply":"2024-11-17T07:49:41.951062Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def infer_single_comment(model, comment):\n    model.eval()\n    # Tokenize input text\n    encoding = tokenizer(comment, padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n    \n#     # Prepare mask for polarity prediction\n#     batch_size = 1  # Single inference\n#     polarity_mask = torch.ones(batch_size, num_aspect).float()\n\n    # No labels provided in inference\n    with torch.no_grad():\n        output,loss = model(input_ids, labels=None, mask=attention_mask)\n\n    pred_category = output['pred_category']\n    pred_sentiment = output['pred_sentiment']\n#     # Extract category and sentiment predictions\n#     pred_category = [torch.sigmoid(e).item() for e in output['pred_category']]\n#     pred_sentiment = [torch.argmax(e).item() for e in output['pred_sentiment']]\n\n    # Map indices to actual labels\n    # aspect_labels = list(aspect2idx.keys())\n    # sentiment_labels = list(sentiment2idx.keys())\n    # results = {\n    #     \"Aspect\": [aspect_labels[i] for i, val in enumerate(pred_category) if val >= 0.5],\n    #     \"Sentiment\": [sentiment_labels[s] for s in pred_sentiment if s > 0]\n    # }\n    return pred_category,pred_sentiment","metadata":{"execution":{"iopub.status.busy":"2024-11-17T07:49:41.953210Z","iopub.execute_input":"2024-11-17T07:49:41.953523Z","iopub.status.idle":"2024-11-17T07:49:41.961901Z","shell.execute_reply.started":"2024-11-17T07:49:41.953491Z","shell.execute_reply":"2024-11-17T07:49:41.961141Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# model.eval()\n# batch = next(iter(train_dataloader))\n# input_ids = batch['input_ids'][0]\n# att_mask = batch['attention_mask'][0]\n# out = model(input_ids, labels=None, mask=att_mask)\n# out['pred_category']\n# # metric = calculate_macro_metrics(categories, sentiments, batch['labels'], num_aspect=10)\n# # metric","metadata":{"execution":{"iopub.status.busy":"2024-11-17T07:49:41.963008Z","iopub.execute_input":"2024-11-17T07:49:41.964057Z","iopub.status.idle":"2024-11-17T07:49:41.977602Z","shell.execute_reply.started":"2024-11-17T07:49:41.964015Z","shell.execute_reply":"2024-11-17T07:49:41.976791Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def calculate_macro_metrics(all_pred_categories, all_pred_sentiments, all_true_labels, num_aspect=10):\n    \"\"\"\n    Calculate macro-averaged Precision, Recall, and F1-score for Aspect Detection and Sentiment Detection.\n\n    Parameters:\n    - all_pred_categories: List of predicted categories (Aspect Detection) for each instance\n    - all_pred_sentiments: List of predicted sentiments (Sentiment Detection) for each instance\n    - all_true_labels: List of true labels with aspect and sentiment information\n    - num_aspect: The number of aspect labels (to split the labels correctly)\n\n    Returns:\n    - Dictionary with macro-averaged Precision, Recall, and F1-score for Aspect and Sentiment Detection\n    \"\"\"\n\n    # Separate true labels into aspects and sentiments based on num_aspect\n    true_acd = [label[:num_aspect] for label in all_true_labels]  # True Aspect Detection labels\n    true_acsa = [label[num_aspect:] for label in all_true_labels]  # True Sentiment Detection labels\n\n    # Flatten lists if needed (this step assumes true_acd and true_acsa are lists of lists)\n    true_acd = [item for sublist in true_acd for item in sublist]\n    true_acsa = [item for sublist in true_acsa for item in sublist]\n\n    pred_acd = [item for sublist in all_pred_categories for item in sublist]\n    pred_acsa = [item for sublist in all_pred_sentiments for item in sublist]\n\n    # Calculate Precision, Recall, and F1-score for Aspect Detection\n    acd_precision = precision_score(true_acd, pred_acd, average=\"macro\", zero_division=0)\n    acd_recall = recall_score(true_acd, pred_acd, average=\"macro\", zero_division=0)\n    acd_f1 = f1_score(true_acd, pred_acd, average=\"macro\", zero_division=0)\n\n    # Calculate Precision, Recall, and F1-score for Sentiment Detection\n    acsa_precision = precision_score(true_acsa, pred_acsa, average=\"macro\", zero_division=0)\n    acsa_recall = recall_score(true_acsa, pred_acsa, average=\"macro\", zero_division=0)\n    acsa_f1 = f1_score(true_acsa, pred_acsa, average=\"macro\", zero_division=0)\n\n    return {\n        \"Aspect Detection\": {\n            \"Precision\": acd_precision * 100,\n            \"Recall\": acd_recall * 100,\n            \"F1-score\": acd_f1 * 100,\n        },\n        \"Sentiment Detection\": {\n            \"Precision\": acsa_precision * 100,\n            \"Recall\": acsa_recall * 100,\n            \"F1-score\": acsa_f1 * 100,\n        }\n    }\n    ","metadata":{"execution":{"iopub.status.busy":"2024-11-17T07:49:41.978617Z","iopub.execute_input":"2024-11-17T07:49:41.978956Z","iopub.status.idle":"2024-11-17T07:49:41.990366Z","shell.execute_reply.started":"2024-11-17T07:49:41.978916Z","shell.execute_reply":"2024-11-17T07:49:41.989599Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def eval_dev(model, dev_dataloader):\n    model.eval()\n    \n    with torch.inference_mode():\n        loss=0\n        pred_cate = []\n        pred_sent = []\n        true_label = []\n        \n        for batch in dev_dataloader:\n            input_ids = batch['input_ids'].to(device)\n            labels = batch['labels'].to(device)\n            att_mask = batch['attention_mask'].to(device)\n            output, loss = model(input_ids, labels, att_mask)\n            l2_reg = torch.tensor(0., requires_grad=False)  # Initialize L2 regularization term\n            for param in model.parameters():\n#                 if param not in model.lstm.parameters():\n                l2_reg = l2_reg + torch.norm(param, 2)  # Add squared norm of each parameter\n\n            # Add L2 regularization term to loss\n            loss = loss + l2_lambda * l2_reg\n            \n            pred_cate.append(output['pred_category'])\n            pred_sent.append(output['pred_sentiment'])\n            true_label.append(batch['labels'])\n    categories = torch.cat(pred_cate, dim=0)\n    sentiments = torch.cat(pred_sent, dim=0)\n    labels = torch.cat(true_label, dim=0)\n    metric = calculate_macro_metrics(categories, sentiments, labels)\n    f1_acd = metric['Aspect Detection']['F1-score']\n    f1_sc = metric['Sentiment Detection']['F1-score']\n    \n    loss = loss / len(dev_dataloader)\n    return loss, f1_acd, f1_sc","metadata":{"execution":{"iopub.status.busy":"2024-11-17T07:49:41.991411Z","iopub.execute_input":"2024-11-17T07:49:41.991975Z","iopub.status.idle":"2024-11-17T07:49:42.004708Z","shell.execute_reply.started":"2024-11-17T07:49:41.991933Z","shell.execute_reply":"2024-11-17T07:49:42.003918Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# l = []\n# a = torch.randn((3,10))\n# b = torch.randn((3,10))\n# l.append(a)\n# l.append(b)\n# c = torch.cat(l, dim=0)\n# c.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-17T07:49:42.005730Z","iopub.execute_input":"2024-11-17T07:49:42.006074Z","iopub.status.idle":"2024-11-17T07:49:42.017426Z","shell.execute_reply.started":"2024-11-17T07:49:42.006034Z","shell.execute_reply":"2024-11-17T07:49:42.016586Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Training loop\nepochs = 50\nl2_lambda = 0.01\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n    pred_cate = []\n    pred_sent = []\n    true_label = []\n    \n    for batch in tqdm(train_dataloader):\n        optimizer.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        labels = batch['labels'].to(device)\n        att_mask = batch['attention_mask'].to(device)\n        output, loss = model(input_ids, labels, att_mask)\n#         output, loss = model(batch['input_ids'], batch['labels'], batch['attention_mask'])\n        l2_reg = torch.tensor(0., requires_grad=True)  # Initialize L2 regularization term\n        for param in model.parameters():\n#             if param not in model.lstm.parameters():\n            l2_reg = l2_reg + torch.norm(param, 2)  # Add squared norm of each parameter\n\n        # Add L2 regularization term to loss\n        loss = loss + l2_lambda * l2_reg\n        \n        pred_cate.append(output['pred_category'])\n        pred_sent.append(output['pred_sentiment'])\n        true_label.append(batch['labels'])\n        \n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)  # Gradient clipping\n        optimizer.step()\n        total_loss += loss.item()\n        \n        \n    # metric\n    categories = torch.cat(pred_cate, dim=0)\n    sentiments = torch.cat(pred_sent, dim=0)\n    labels = torch.cat(true_label, dim=0)\n#     print(labels.shape)\n#     print(categories.shape)\n#     print(sentiment.shape)\n    metric = calculate_macro_metrics(categories, sentiments, labels)\n    f1_acd = metric['Aspect Detection']['F1-score']\n    f1_sc = metric['Sentiment Detection']['F1-score']\n    dev = eval_dev(model, dev_dataloader)\n    \n    print(f\"Epoch {epoch + 1} - Train_Loss: {total_loss / len(train_dataloader)} - train_acd_f1: {f1_acd} - train_sc_f1: {f1_sc}\")\n    print(f\"dev_loss: {dev[0]} - dev_acd_f1: {dev[1]} - dev_sc_f1: {dev[2]}\")\n    \n    if epoch%10==0 and epoch>0:\n        torch.save(model.state_dict(), f\"CAE_checkpoint{epoch+1}.pth\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OGWtu3FZViZA","executionInfo":{"status":"error","timestamp":1731780951900,"user_tz":-420,"elapsed":10851,"user":{"displayName":"Trường Nguyễn","userId":"01798196861580803215"}},"outputId":"4f5c0ec9-977a-40c7-b199-d85e516b4126","execution":{"iopub.status.busy":"2024-11-17T07:49:42.018721Z","iopub.execute_input":"2024-11-17T07:49:42.018996Z","iopub.status.idle":"2024-11-17T07:54:21.124533Z","shell.execute_reply.started":"2024-11-17T07:49:42.018966Z","shell.execute_reply":"2024-11-17T07:54:21.123418Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"  0%|          | 0/61 [00:00<?, ?it/s]/tmp/ipykernel_31/3054169716.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(self.labels[idx], dtype=torch.float32)\n100%|██████████| 61/61 [00:13<00:00,  4.45it/s]\n/tmp/ipykernel_31/3054169716.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(self.labels[idx], dtype=torch.float32)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 - Train_Loss: 44.215947885982324 - train_acd_f1: 27.78286958934335 - train_sc_f1: 13.577583442124114\ndev_loss: 4.624623775482178 - dev_acd_f1: 52.236938251116236 - dev_sc_f1: 26.021927127646876\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/61 [00:00<?, ?it/s]/tmp/ipykernel_31/3054169716.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(self.labels[idx], dtype=torch.float32)\n100%|██████████| 61/61 [00:11<00:00,  5.22it/s]\n/tmp/ipykernel_31/3054169716.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(self.labels[idx], dtype=torch.float32)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 - Train_Loss: 40.951784540395266 - train_acd_f1: 62.50434942159874 - train_sc_f1: 42.45135516543368\ndev_loss: 4.440301895141602 - dev_acd_f1: 72.73929684423581 - dev_sc_f1: 53.73066236181517\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/61 [00:00<?, ?it/s]/tmp/ipykernel_31/3054169716.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(self.labels[idx], dtype=torch.float32)\n100%|██████████| 61/61 [00:11<00:00,  5.30it/s]\n/tmp/ipykernel_31/3054169716.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(self.labels[idx], dtype=torch.float32)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 - Train_Loss: 38.893184349185134 - train_acd_f1: 72.26480823409528 - train_sc_f1: 52.704943295978524\ndev_loss: 4.123592376708984 - dev_acd_f1: 77.49475885416548 - dev_sc_f1: 57.55226716872406\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/61 [00:00<?, ?it/s]/tmp/ipykernel_31/3054169716.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(self.labels[idx], dtype=torch.float32)\n100%|██████████| 61/61 [00:11<00:00,  5.36it/s]\n/tmp/ipykernel_31/3054169716.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(self.labels[idx], dtype=torch.float32)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 - Train_Loss: 37.593412055343876 - train_acd_f1: 76.05649047038963 - train_sc_f1: 56.555556616126005\ndev_loss: 4.000006198883057 - dev_acd_f1: 80.83204545493314 - dev_sc_f1: 60.63882042210944\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/61 [00:00<?, ?it/s]/tmp/ipykernel_31/3054169716.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(self.labels[idx], dtype=torch.float32)\n100%|██████████| 61/61 [00:11<00:00,  5.36it/s]\n/tmp/ipykernel_31/3054169716.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(self.labels[idx], dtype=torch.float32)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 - Train_Loss: 36.63625542062228 - train_acd_f1: 78.29876948044551 - train_sc_f1: 58.48371537253809\ndev_loss: 4.053582668304443 - dev_acd_f1: 82.5527155996876 - dev_sc_f1: 61.40835194548882\n","output_type":"stream"}]},{"cell_type":"code","source":"# torch.save(model.state_dict(), \"CAE_ignore_test_lstm.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-11-17T07:54:21.125798Z","iopub.execute_input":"2024-11-17T07:54:21.126086Z","iopub.status.idle":"2024-11-17T07:54:21.196890Z","shell.execute_reply.started":"2024-11-17T07:54:21.126055Z","shell.execute_reply":"2024-11-17T07:54:21.195953Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# model1 = Cae(embedding_layer, categories, polarities)\n# model1.load_state_dict(torch.load('/kaggle/working/CAE_ignore_test_lstm.pth'))\n# model1.eval()\n# model1.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample_comment = train.iloc[1]['comment']\n# x, y = infer_single_comment(model=model, comment=sample_comment)\n# print(\"pred_cate\", x)\n# print(\"pred_sent\", y) #strict=False","metadata":{"execution":{"iopub.status.busy":"2024-11-17T08:16:39.727365Z","iopub.execute_input":"2024-11-17T08:16:39.727760Z","iopub.status.idle":"2024-11-17T08:16:39.748674Z","shell.execute_reply.started":"2024-11-17T08:16:39.727725Z","shell.execute_reply":"2024-11-17T08:16:39.747760Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"pred_cate tensor([[0, 1, 1, 0, 0, 1, 0, 0, 0, 0]])\npred_sent tensor([[-1,  0,  0, -1, -1,  0, -1, -1, -1, -1]])\n","output_type":"stream"}]},{"cell_type":"code","source":"# aspect2idx = {\n#     'CAMERA': 0, 'FEATURES': 1, 'BATTERY': 2, 'PERFORMANCE': 3,\n#     'DESIGN': 4, 'GENERAL': 5, 'PRICE': 6, 'SCREEN': 7, 'SER&ACC': 8, 'STORAGE': 9\n# }\n# sentiment2idx = {\n#     'Positive': 2, 'Neutral': 1, 'Negative': 0\n# }","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train.iloc[1]['label']","metadata":{"execution":{"iopub.status.busy":"2024-11-17T08:01:52.374494Z","iopub.execute_input":"2024-11-17T08:01:52.374884Z","iopub.status.idle":"2024-11-17T08:01:52.382153Z","shell.execute_reply.started":"2024-11-17T08:01:52.374846Z","shell.execute_reply":"2024-11-17T08:01:52.381109Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"'[ 0.  0.  1.  0.  0.  1.  0.  0.  0.  0. -1. -1.  0. -1. -1.  2. -1. -1.\\n -1. -1.]'"},"metadata":{}}]},{"cell_type":"code","source":"# model1.eval()\n\n# with torch.no_grad():\n#     batch = next(iter(train_dataloader))\n#     input_ids = batch['input_ids'].to(device)\n#     labels = batch['labels'].to(device)\n#     att_mask = batch['attention_mask'].to(device)\n#     output, loss = model1(input_ids, labels, att_mask)\n#     print(output['pred_category'].shape) ","metadata":{"execution":{"iopub.status.busy":"2024-11-17T07:54:21.216405Z","iopub.execute_input":"2024-11-17T07:54:21.216690Z","iopub.status.idle":"2024-11-17T07:54:21.225791Z","shell.execute_reply.started":"2024-11-17T07:54:21.216660Z","shell.execute_reply":"2024-11-17T07:54:21.224997Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# x.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-17T07:54:21.226741Z","iopub.execute_input":"2024-11-17T07:54:21.226988Z","iopub.status.idle":"2024-11-17T07:54:21.234757Z","shell.execute_reply.started":"2024-11-17T07:54:21.226960Z","shell.execute_reply":"2024-11-17T07:54:21.234006Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# đọc lại paper\n# check lại data\n# xem model build đúng chưa\n\n# viết hàm eval\n#   2 task riêng\n#   gộp lại\n# binary F1 cho ACD\n# accuracy cho SC\n# F1 cho ACSC\n\n# train model\n# print ra metric\n# eval treen tap dev\n\n# viết hàm inference\n\n\n## case studies\n\n## hyperparams\n# dropout rate\n# embed dim\n# clip_norm\n# lr, scheduler\n# threshold\n\n# exclude lstm\n# function for batch","metadata":{"id":"Q20TXWa9p2IL","execution":{"iopub.status.busy":"2024-11-17T07:54:21.236001Z","iopub.execute_input":"2024-11-17T07:54:21.236337Z","iopub.status.idle":"2024-11-17T07:54:21.245466Z","shell.execute_reply.started":"2024-11-17T07:54:21.236296Z","shell.execute_reply":"2024-11-17T07:54:21.244535Z"},"trusted":true},"execution_count":26,"outputs":[]}]}